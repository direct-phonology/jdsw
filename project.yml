title: "Parsing the _Jingdian Shiwen_"
description: |
  [![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://direct-phonology-jdsw-scriptsvisualize-0px83h.streamlit.app/)
  
  This project is an attempt to convert the annotations compiled by the Tang dynasty scholar [Lu Deming (陸德明)](https://en.wikipedia.org/wiki/Lu_Deming) in the [_Jingdian Shiwen_ (经典释文)](https://en.wikipedia.org/wiki/Jingdian_Shiwen) into a structured form that separates phonology, glosses, and references to secondary sources. A [spaCy](https://spacy.io/) pipeline is configured to parse and tag the annotations, and [prodigy](https://prodi.gy/) is used for guided annotation of the training data.

  The source text used is from the [Kanseki Repository](https://www.kanripo.org/), and has been preprocessed to remove punctuation, whitespace, and any non-Chinese characters. The results are saved in JSON-lines (`.jsonl`) format, with the aim being output that can be used for machine learning, natural language processing, and other computational applications.

  ## Annotating data
  To annotate training data, you need to have spacy installed in your python environment:
  ```sh
  pip install spacy
  ```
  You also need a copy of [prodigy](https://prodi.gy/). Once you have the appropriate wheel, install it with:
  ```sh
  # example: prodigy version 1.11.8 for python 3.10 on windows
  pip install prodigy-1.11.8-cp310-cp310-win_amd64.whl
  ```
  Then, verify the project assets are downloaded:
  ```sh
  spacy project assets
  ```
  Install python dependencies needed for annotation:
  ```sh
  spacy project run install
  ```
  Then, choose an annotation task (see "commands" below). Invoke it with:
  ```sh
  # example: annotate parts-of-speech
  spacy project run pos
  ```

# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  dataset: "jdsw_annotations"
  lang: "lzh"
  gpu_id: -1
  eval_split: 0.25

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "configs", "corpus", "metrics", "packages", "scripts", "training"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that the checksums match.
assets:
  - dest: "assets/annotations.jsonl"
    description: "Corpus of annotations from the _Jingdian Shiwen_, including their headwords."
  - dest: "assets/ner_patterns.jsonl"
    description: "Patterns for pre-selecting regions in annotation text."

# Workflows are series of commands that are run in order and often depend on 
# each other.
# workflows: []

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "install"
    help: "Install dependencies"
    script:
      - "python -m pip install -r requirements.txt"

  - name: "pos"
    help: "Annotate parts of speech by correcting an existing model"
    script:
      - "python -m prodigy suparkanbun.pos.correct ${vars.dataset} assets/pos_sample.jsonl -F scripts/recipes.py"
    deps:
      - "assets/pos_sample.jsonl"
